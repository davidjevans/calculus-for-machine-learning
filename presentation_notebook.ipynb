{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17d5c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecea07e9",
   "metadata": {},
   "source": [
    "# Creating the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b129a9",
   "metadata": {},
   "source": [
    "To create a linear regression dataset, we need to create a bunch of random points along a line. The way we'll do this is by:\n",
    "1. Using `numpy` to sample a bunch of random x values.\n",
    "1. Map the random x values to y values on a line.\n",
    "1. Add noise to the y values so they don't sit perfectly on the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa55850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The weights for the line we're going sample from\n",
    "true_weights = {'m': 1, 'b': 1.5}\n",
    "\n",
    "# These are the lower and upper bounds of the x values numpy will sample\n",
    "min_x_range = 0\n",
    "max_x_range = 10\n",
    "\n",
    "# The number of points in our dataset.\n",
    "num_samples = 50\n",
    "\n",
    "# How much jitter we want to add onto the y values.\n",
    "noise_factor = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664102a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly sample a bunch of x values between min_x_range and max_x_range.\n",
    "x_val = np.random.uniform(min_x_range, max_x_range, num_samples)\n",
    "\n",
    "# Map the random x values to y values on the line.\n",
    "y_line = true_weights['m'] * x_val + true_weights['b']\n",
    "\n",
    "# Add noise to the y values so they don't sit perfectly on the line.\n",
    "y_val = y_line + np.random.uniform(-noise_factor, noise_factor, num_samples)\n",
    "\n",
    "# Let's store our dataset in an easily accesible form (called a pandas DataFrame)\n",
    "dataset = pd.DataFrame({'x': x_val, 'y': y_val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19a00a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's view at our dataset!\n",
    "fig = px.scatter(x=dataset['x'], y=dataset['y'])\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"X values\",\n",
    "    yaxis_title=\"Y values\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af97dcc7",
   "metadata": {},
   "source": [
    "# Defining the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b414315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are some functions that we're about to use in a second\n",
    "def poly_coeffs(x, coeffs):\n",
    "    order = len(coeffs)\n",
    "    y = 0\n",
    "    for i in range(order):\n",
    "        y += coeffs[i]*x**i\n",
    "    return y\n",
    "\n",
    "def draw_L_by_m(dataset, weights):\n",
    "    \"\"\"\n",
    "    Draws the loss as a function of weight m\n",
    "    \n",
    "    Args:\n",
    "        dataset: the dataset of x, y pairs\n",
    "        weights: the optimal m and b weights\n",
    "    \"\"\"\n",
    "    a, b, c = 0, 0, 0\n",
    "    for _, point in dataset.iterrows():\n",
    "        a += point['x']**2\n",
    "        b += -2 * point['x'] * point['y'] + 2 * weights['b'] * point['x']\n",
    "        c += -2 * weights['b'] * point['y'] + weights['b']**2 + point['y']**2\n",
    "    a /= len(dataset)\n",
    "    b /= len(dataset)\n",
    "    c /= len(dataset)\n",
    "    \n",
    "    x = np.linspace(-4, 6, 100)\n",
    "    plt.plot(x, poly_coeffs(x, [c, b, a]))\n",
    "    plt.ylabel(\"Value of Loss\")\n",
    "    plt.xlabel(\"Value of m (slope)\")\n",
    "    plt.show()\n",
    "    \n",
    "def draw_L_by_b(dataset, weights):\n",
    "    \"\"\"\n",
    "    Draws the loss as a function of weight b\n",
    "    \n",
    "    Args:\n",
    "        dataset: the dataset of x, y pairs\n",
    "        weights: the optimal m and b weights\n",
    "    \"\"\"\n",
    "    a, b, c = 0, 0, 0\n",
    "    print(weights)\n",
    "    for _, point in dataset.iterrows():\n",
    "        a += 1\n",
    "        b += 2 * weights['m'] * point['x'] - 2 * point['y']\n",
    "        c += point['x']**2 * weights['m']**2 \\\n",
    "             - 2 * weights['m'] * point['x'] * point['y'] + point['y']**2\n",
    "    a /= len(dataset)\n",
    "    b /= len(dataset)\n",
    "    c /= len(dataset)\n",
    "    x = np.linspace(-3.5, 6.5, 100)\n",
    "    plt.plot(x, poly_coeffs(x, [c, b, a]))\n",
    "    plt.ylabel(\"Value of Loss\")\n",
    "    plt.xlabel(\"Value of b (y-intercept)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daa1b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's our loss as a function of m\n",
    "# You could try and take the derivative of this polynomial, but there's a problem...\n",
    "# We're drawing this polynomials with the true weights. We don't actually know them...\n",
    "draw_L_by_m(dataset, true_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0917ade9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's our loss as a function of b\n",
    "draw_L_by_b(dataset, true_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac6c6c7",
   "metadata": {},
   "source": [
    "# Learning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8824fc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are some functions that we're going to use to help learn the model\n",
    "def draw_plot_and_model(dataset, weights):\n",
    "    \"\"\"\n",
    "    Draws the dataset and the model on a plot.\n",
    "    \n",
    "    Args:\n",
    "        dataset: the dataset of x, y pairs\n",
    "        weights: these are the weights of the model you want drawn. It should have an m and b.\n",
    "        \n",
    "    Returns:\n",
    "        Plotly figure with visualized dataset and model\n",
    "    \"\"\"\n",
    "    # This will be used to draw current model's regression line\n",
    "    line_df = pd.DataFrame(dict(\n",
    "        x = [dataset['x'].min(), dataset['x'].max()],\n",
    "        y = [weights['m'] * dataset['x'].min() + weights['b'], \n",
    "             weights['m'] * dataset['x'].max() + weights['b']]\n",
    "    ))\n",
    "    # Draw our model's regression line\n",
    "    fig_line = px.line(line_df, x=\"x\", y=\"y\")\n",
    "    fig_line.update_traces(line_color='red', line_width=4)\n",
    "\n",
    "    # Draw our dataset's points\n",
    "    fig_scat = px.scatter(x=dataset['x'], y=dataset['y'])\n",
    "\n",
    "    # Draw the points and regression line together\n",
    "    fig_final = go.Figure(data=fig_line.data + fig_scat.data)\n",
    "    fig_final.update_layout(\n",
    "        xaxis_title=\"X values\",\n",
    "        yaxis_title=\"Y values\")\n",
    "    \n",
    "    return fig_final\n",
    "\n",
    "def dL_dm(weights, point):\n",
    "    \"\"\"\n",
    "    Returns the value of the derivative of the loss with respect\n",
    "    to m at given points and weights.\n",
    "    \n",
    "    Args:\n",
    "        weights: m, b weights to calculate loss derivative at.\n",
    "        point: x, y point to calculate loss derivative at.\n",
    "        \n",
    "    Returns:\n",
    "        Value of dL/dm at point and weights.\n",
    "\n",
    "    \"\"\"\n",
    "    # We did the math in class:\n",
    "    # dL/dm = -2x * (y - mx - b)\n",
    "    return -2 * point['x'] * (point['y'] - weights['m'] * point['x'] - weights['b'])\n",
    "\n",
    "def dL_db(weights, point):\n",
    "    \"\"\"\n",
    "    Returns the value of the derivative of the loss with respect\n",
    "    to b at given points and weights.\n",
    "    \n",
    "    Args:\n",
    "        weights: m, b weights to calculate loss derivative at.\n",
    "        point: x, y point to calculate loss derivative at.\n",
    "        \n",
    "    Returns:\n",
    "        Value of dL/db at point and weights.\n",
    "    \"\"\"\n",
    "    # We did the math in class:\n",
    "    # dL/db = -2 * (y - mx - b)\n",
    "    return -2 * (point['y'] - weights['m'] * point['x'] - weights['b'])\n",
    "\n",
    "def take_step(weights, point):\n",
    "    \"\"\"\n",
    "    With the current weights and point, calculate the new weights \n",
    "    in the direction of the optimal weights.\n",
    "    \n",
    "    Args:\n",
    "        weights: m, b weights to calculate loss derivative at\n",
    "        point: x, y point to calculate loss derivative at\n",
    "        \n",
    "    Returns:\n",
    "        The new weights\n",
    "    \"\"\"\n",
    "    # Our \"learning rate\". This is what makes us take baby steps.\n",
    "    # Fun activity: What happens when you make this bigger? What about smaller? Is it possible to be too big??\n",
    "    lr = 1e-3\n",
    "\n",
    "    # Update the weights m and b\n",
    "    weights['m'] = weights['m'] - lr*dL_dm(weights, point)\n",
    "    weights['b'] = weights['b'] - lr*dL_db(weights, point)\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4d9927",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabb021b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Pick our random weights\n",
    "# Note: these aren't really random right now because I want a visually appealing initial model\n",
    "weights = {'m': -0.25,'b': 5}\n",
    "\n",
    "# Let's draw our model and see the initial model with our data \n",
    "draw_plot_and_model(dataset, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062c8d55",
   "metadata": {},
   "source": [
    "## First step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e049808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's sample a random point\n",
    "rand_idx = np.random.randint(len(dataset))\n",
    "point = dataset.iloc[rand_idx]\n",
    "\n",
    "# And take a step calculating our new weights\n",
    "new_weights = take_step(weights, point)\n",
    "\n",
    "# Set our old weights to our new weights\n",
    "weights = new_weights\n",
    "\n",
    "fig = draw_plot_and_model(dataset, weights)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f538ce",
   "metadata": {},
   "source": [
    "## Second step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cfeb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's sample another random point\n",
    "rand_idx = np.random.randint(len(dataset))\n",
    "point = dataset.iloc[rand_idx]\n",
    "\n",
    "# And take another step calculating our new weights\n",
    "new_weights = take_step(weights, point)\n",
    "\n",
    "# Set our old weights to our new weights\n",
    "weights = new_weights\n",
    "\n",
    "fig = draw_plot_and_model(dataset, weights)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b462835b",
   "metadata": {},
   "source": [
    "## Tenth step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9f989c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we do this 10x in a row\n",
    "# Does the plot look any better?\n",
    "for _ in range(2, 10):\n",
    "    # Let's sample a random point\n",
    "    rand_idx = np.random.randint(len(dataset))\n",
    "    point = dataset.iloc[rand_idx]\n",
    "\n",
    "    # And take a step calculating our new weights\n",
    "    new_weights = take_step(weights, point)\n",
    "\n",
    "    # Set our old weights to our new weights\n",
    "    weights = new_weights\n",
    "\n",
    "fig = draw_plot_and_model(dataset, weights)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0d930c",
   "metadata": {},
   "source": [
    "## Five thousandth step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6f13b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# How about 5000x in a row\n",
    "# Does the plot look any better?\n",
    "for _ in range(10, 5000):\n",
    "    # Let's sample a random point\n",
    "    rand_idx = np.random.randint(len(dataset))\n",
    "    point = dataset.iloc[rand_idx]\n",
    "\n",
    "    # And take a step calculating our new weights\n",
    "    new_weights = take_step(weights, point)\n",
    "\n",
    "    # Set our old weights to our new weights\n",
    "    weights = new_weights\n",
    "\n",
    "fig = draw_plot_and_model(dataset, weights)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2cc011",
   "metadata": {},
   "source": [
    "# Fun challenges for yourself"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970240ec",
   "metadata": {},
   "source": [
    "* Try changing the value of `lr`. How does that affect the number of steps you need to get a good looking model?\n",
    "* Try a different loss function: absolute value, log-cosh error, huber loss\n",
    "* Can you change this to estimate a polynomial instead of a line?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
